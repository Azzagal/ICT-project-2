\documentclass[]{template}

% En-tÃªte
\renewcommand{\headrulewidth}{0.1pt}
\fancyhead[C]{} 
\fancyhead[L]{\rightmark}
\fancyhead[R]{\thepage}

% Pied de page
\newcommand{\tablemat}{~}
\renewcommand{\tablemat}{\tableofcontents}
\renewcommand{\footrulewidth}{0.1pt}
\fancyfoot[C]{} %\textbf{\thepage} 
\fancyfoot[L]{}
\fancyfoot[R]{Source coding, data compression and
channel coding}

\begin{document}

\begin{guardpage}
    \academicyear{2024-2025}
    %\guardimage{de}{0.8}
    \addtitle{ELEN0060-2: Project 2}{Source coding, data compression and
    channel coding}
    \begin{authors}{0.18}
        \addauthor{Pierre}{Lorenzen}{S203724}
        \addauthor{Abdelilah}{Khaliphi}{S204896}
    \end{authors}

\end{guardpage}

\newpage
\tablemat
\newpage

\section{Implementation}

    \subsection{Question 1}
        In the implementation for this question, we first define a node class to facilitate the creation and management of the binary tree used in the Huffman coding algorithm.\\
        
        \noindent
        Secondly, iteratively, we sort the nodes based on their probabilities at each iteration, and we merge the two lowest probabilities. This node created
        by the merge of the two lowest probabilities ones is then added to the tree with a probability equal to the sum of the two lowest probabilities. 
        The children nodes are the two nodes that were merged. The process is repeated until we have a single node left, which is the root of the tree. \\

        \noindent
        Tirdly, we generate the codes for each symbol by traversing the tree. We start at the root and assign a '0' code to the left child and a '1' code to
        the right child. We continue this process recursively until we reach a leaf node, at which point we store the generated code for that symbol.\\

        \noindent
        Finally, we reorder the symbols to be consistent with the order provided at the input of the function.\\

        \noindent
        To extend the Huffman code generation to any alphabet size $q$, we can modify the algorithm to merge the q lowest-probabilities
        nodes at each step and so build a q-ary tree, where each node has up to $q$ children.\\
        
        \noindent
        To implement this with a number of input symbols $n$ and output alphabet size of $q \geq 2$, we can
        
        \begin{enumerate}
            \item Take the $n$ symbols with their probabilities
            \item Add Dummy Symbols: If $(n-1) \; mod \; (q-1) \neq  0$, add dummy symbols of probability 0 so that:
            $(n' - 1) \; mod \; (q-1)=0$
            
            where n' is the total number of symbols (real + dummy).
            \item Maintain nodes sorted by probability.  
            \item Merge q smallest-nodes.
            \item Repeat until only one node is left.
            \item Label the edges with 0,1,...,q-1.
        \end{enumerate}
        
    \subsection{Question 2}

    \subsection{Question 3}

    As explained in the theoretical course, the Lempel-Ziv algorithms can be compared on several aspects. These aspects are the dictionary construction,
    the parsing of the input data, the encoding, the dictionary address size, the adaptivity of the algorithm, the efficiency, and the on-line capability.
    
    \begin{table}[]
        \centering
        \begin{tabular}{|l|c|l|}
        \hline
        \multicolumn{1}{|c|}{Aspect} & \multicolumn{1}{l|}{Basic Lempel-Ziv}                                                                      & On-line Lempel-Ziv                                      \\ \hline
                                     &                                                                                                            &                                                         \\ \hline
        Dictionary construction      & Grows incrementally by adding new words                                                                    & Same as basic                                           \\ \hline
        Parsing                      & Greedy: find the longest prefix in dictionary                                                              & Same as basic                                           \\ \hline
        Encoding                     & a tuple (address of prefix, next symbol)                                                                   & Same as basic but the address is encoded dynamically    \\ \hline
        Dictionary address size      & \begin{tabular}[c]{@{}c@{}}Fixed-size = $2^n$ \\ Where n is the number of bits\end{tabular}                & Variable-length based on current dictionary size        \\ \hline
        Adaptivity                   & No adaptation done based on the dictionary                                                                 & fewer bits used at early stages                         \\ \hline
        Efficiency                   & Good compression when the dictionary is large                                                              & More efficient in early stages due to shorter addresses \\ \hline
        On-line capability           & No                                                                                                         & Yes it can transmit as the text is read                 \\ \hline
        \end{tabular}
        \end{table}

    \noindent
    Base on this comparison, we can conclude that the advantages of the basic Lempel-Ziv algorithm are that the compression on large dictionary is 
    more efficient than the on-line Lempel-Ziv algorithm, and that the dictionary address size is fixed. 
    The backwards of this version is that it is not adaptive, and it is not on-line.\\

    \noindent
    The advantages of the on-line Lempel-Ziv algorithm are that it is adaptive, on small and medium dictionary size the efficiency is better due to the shorter addresses, and it is on-line. The backwards of this version is that the compression
    on large dictionary is less efficient than the basic Lempel-Ziv algorithm, and that the dictionary address size is variable.\\

    \subsection{Question 4}

\section{Source coding and reversible (lossless) data compression}

    \subsection{Question 5}

    \subsection{Question 6}

    \subsection{Question 7}

    \subsection{Question 8}

    \subsection{Question 9}

    \subsection{Question 10}

    \subsection{Question 11}

    \subsection{Question 12}

    \subsection{Question 13}

    \subsection{Question 14}

    \subsection{Question 15}

    \subsection{Question 16}

\section{Channel coding}

    \subsection{Question 17}

    \subsection{Question 18}

    \subsection{Question 19}

    \subsection{Question 20}

    \subsection{Question 21}

    \subsection{Question 22}

\end{document}
